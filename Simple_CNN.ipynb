{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Simple_CNN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5ikuH6SyzZk2","colab_type":"text"},"source":["## Convolutional Neural Network\n","\n","Trains a CNN\n","\n","## How to use\n","1) Set the parameters to fit your needs and environment\n","\n","2) Run All blocks\n","\n","3) Allow google drive to be mounted\n","\n","4) Wait"]},{"cell_type":"markdown","metadata":{"id":"z-YZCluH-iQg","colab_type":"text"},"source":["### Parameters"]},{"cell_type":"code","metadata":{"id":"OaNg4Yr--nCM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596310281833,"user_tz":420,"elapsed":349,"user":{"displayName":"Colton Davenport","photoUrl":"","userId":"13788767686338694290"}}},"source":["# Set true or false depending on wether training a new network \n","# or continuing to train an old one\n","CONTINUNING_RUN = False\n","\n","\n","# Name the model you will be training\n","#   the model name will be used for checkpoints \n","MODEL_NAME = \"CNN_TEST\"\n","\n","# Give the path for the training and validation tfRecords\n","#   Training records are assumed to follow pattern train_*\n","#   Testing records are assumed to follow pattern val_*\n","RECORD_DIR = 'drive/My Drive/github_prep/welsh-200'\n","CHECKPOINT_DIR = 'drive/My Drive/github_prep/checkpoints'\n","\n","\n","# if continuing to train an old model set this to the appropriate\n","# file, otherwise  this line can be safely ignored \n","MODEL_WEIGHTS_FILEPATH = 'drive/My Drive/datasets/dataset_models_test/denoiser_cnn_log_mel_generator.h5'\n","\n","# Set the batch size, epochs, and steps per epoch for this run\n","EPOCHS = 250\n","STEPS_PER_EPOCH = 200\n","BATCH_SIZE = 768\n","TEST_BATCH_SIZE = 512"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qox4ja3H-p3_","colab_type":"text"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"XiARWW1wFaK6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596310150770,"user_tz":420,"elapsed":1943,"user":{"displayName":"Colton Davenport","photoUrl":"","userId":"13788767686338694290"}},"outputId":"512ec794-5df7-4a18-b374-97448e2197be"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I1DQb4z3exnE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":181},"executionInfo":{"status":"ok","timestamp":1596310153688,"user_tz":420,"elapsed":4850,"user":{"displayName":"Colton Davenport","photoUrl":"","userId":"13788767686338694290"}},"outputId":"d3f50d7f-27fb-456b-cd5a-ab9b3532e676"},"source":["!pip uninstall tensorflow\n","!pip install --upgrade tensorflow-gpu\n","!pip install keras-rectified-adam"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras-rectified-adam in /usr/local/lib/python3.6/dist-packages (0.17.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-rectified-adam) (1.18.5)\n","Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-rectified-adam) (2.3.1)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (1.4.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (2.10.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (1.1.2)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (1.0.8)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (3.13)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FpChwIi4-uiW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":144},"executionInfo":{"status":"ok","timestamp":1596310155913,"user_tz":420,"elapsed":7064,"user":{"displayName":"Colton Davenport","photoUrl":"","userId":"13788767686338694290"}},"outputId":"7a142c51-1dc4-4a19-9767-b63070e392d3"},"source":["import tensorflow as tf\n","\n","import os\n","os.environ['TF_KERAS'] = '1'\n","\n","from keras_radam import RAdam\n","\n","import librosa\n","import os\n","import datetime\n","import numpy as np\n","import tensorflow as tf\n","import glob\n","import warnings\n","from sklearn.utils import shuffle\n","\n","\n","tf.random.set_seed(999)\n","np.random.seed(999)\n","\n","windowLength = 256\n","overlap      = round(0.25 * windowLength) # overlap of 75%\n","ffTLength    = windowLength\n","inputFs      = 48e3\n","fs           = 16e3\n","numFeatures  = ffTLength//2 + 1\n","numSegments  = 8\n","print(\"windowLength:\",windowLength)\n","print(\"overlap:\",overlap)\n","print(\"ffTLength:\",ffTLength)\n","print(\"inputFs:\",inputFs)\n","print(\"fs:\",fs)\n","print(\"numFeatures:\",numFeatures)\n","print(\"numSegments:\",numSegments)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["windowLength: 256\n","overlap: 64\n","ffTLength: 256\n","inputFs: 48000.0\n","fs: 16000.0\n","numFeatures: 129\n","numSegments: 8\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Y5-FlLyY-y5I","colab_type":"text"},"source":["## Prepare Input Features"]},{"cell_type":"code","metadata":{"id":"j93xQ3sb-2C3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596310155916,"user_tz":420,"elapsed":7060,"user":{"displayName":"Colton Davenport","photoUrl":"","userId":"13788767686338694290"}}},"source":["def tf_record_parser(record):\n","    keys_to_features = {\n","        \"noise_stft_phase\": tf.io.FixedLenFeature((), tf.string, default_value=\"\"),\n","        'noise_stft_mag_features': tf.io.FixedLenFeature([], tf.string),\n","        \"clean_stft_magnitude\": tf.io.FixedLenFeature((), tf.string)\n","    }\n","\n","    features = tf.io.parse_single_example(record, keys_to_features)\n","\n","    noise_stft_mag_features = tf.io.decode_raw(features['noise_stft_mag_features'], tf.float32)\n","    clean_stft_magnitude = tf.io.decode_raw(features['clean_stft_magnitude'], tf.float32)\n","    noise_stft_phase = tf.io.decode_raw(features['noise_stft_phase'], tf.float32)\n","\n","    # reshape input and annotation images\n","    noise_stft_mag_features = tf.reshape(noise_stft_mag_features, (129, 8, 1), name=\"noise_stft_mag_features\")\n","    clean_stft_magnitude = tf.reshape(clean_stft_magnitude, (129, 1, 1), name=\"clean_stft_magnitude\")\n","    noise_stft_phase = tf.reshape(noise_stft_phase, (129,), name=\"noise_stft_phase\")\n","\n","    return noise_stft_mag_features, clean_stft_magnitude"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Eqehoi0D-45f","colab_type":"text"},"source":["## Create Dataset"]},{"cell_type":"code","metadata":{"id":"kSLg1JFw-8Ko","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596310367603,"user_tz":420,"elapsed":396,"user":{"displayName":"Colton Davenport","photoUrl":"","userId":"13788767686338694290"}}},"source":["train_tfrecords_filenames = glob.glob(os.path.join(RECORD_DIR, 'train_*'))\n","np.random.shuffle(train_tfrecords_filenames)\n","train_tfrecords_filenames = list(train_tfrecords_filenames)\n","\n","val_tfrecords_filenames = glob.glob(os.path.join(RECORD_DIR, 'test_*'))\n","\n","train_dataset = tf.data.TFRecordDataset([train_tfrecords_filenames])\n","train_dataset = train_dataset.map(tf_record_parser)\n","train_dataset = train_dataset.shuffle(8192)\n","train_dataset = train_dataset.repeat()\n","train_dataset = train_dataset.batch(BATCH_SIZE)\n","train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","\n","test_dataset = tf.data.TFRecordDataset([val_tfrecords_filenames])\n","test_dataset = test_dataset.map(tf_record_parser)\n","test_dataset = test_dataset.repeat(1)\n","test_dataset = test_dataset.batch(TEST_BATCH_SIZE)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"NTBjoa4rHsxt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1596310369336,"user_tz":420,"elapsed":354,"user":{"displayName":"Colton Davenport","photoUrl":"","userId":"13788767686338694290"}},"outputId":"26d9ab70-e7d1-4713-837f-991bd97f259b"},"source":["print(train_tfrecords_filenames)\n","print(val_tfrecords_filenames)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["['drive/My Drive/github_prep/welsh-200/train_0.tfrecords', 'drive/My Drive/github_prep/welsh-200/train_0 (1).tfrecords']\n","['drive/My Drive/github_prep/welsh-200/test_1.tfrecords', 'drive/My Drive/github_prep/welsh-200/test_0.tfrecords']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2AB_qfck_DIe","colab_type":"text"},"source":["## Model Definition"]},{"cell_type":"code","metadata":{"id":"sHiM8Zg-_Lbe","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596310156407,"user_tz":420,"elapsed":7531,"user":{"displayName":"Colton Davenport","photoUrl":"","userId":"13788767686338694290"}}},"source":["## Model Training\n","\n","from tensorflow.keras.layers import Conv2D, Input, LeakyReLU, Flatten, Dense, Reshape, Conv2DTranspose, BatchNormalization, Activation\n","from tensorflow.keras import Model, Sequential\n","\n","def conv_block(x, filters, kernel_size, strides, padding='same', use_bn=True):\n","  x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(0.0006))(x)\n","  x = Activation('relu')(x)\n","  if use_bn:\n","    x = BatchNormalization()(x)\n","  return x\n","\n","def full_pre_activation_block(x, filters, kernel_size, strides, padding='same', use_bn=True):\n","  shortcut = x\n","  in_channels = x.shape[-1]\n","\n","  x = BatchNormalization()(x)\n","  x = Activation('relu')(x)\n","  x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n","\n","  x = BatchNormalization()(x)\n","  x = Activation('relu')(x)\n","  x = Conv2D(filters=in_channels, kernel_size=kernel_size, strides=strides, padding='same')(x)\n","\n","  return shortcut + x\n","\n","def build_model(l2_strength):\n","  inputs = Input(shape=[numFeatures,numSegments,1])\n","  x = inputs\n","\n","  # -----\n","  x = tf.keras.layers.ZeroPadding2D(((4,4), (0,0)))(x)\n","  x = Conv2D(filters=18, kernel_size=[9,8], strides=[1, 1], padding='valid', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  skip0 = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n","                 kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(skip0)\n","  x = BatchNormalization()(x)\n","\n","  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  # -----\n","  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  skip1 = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n","                 kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(skip1)\n","  x = BatchNormalization()(x)\n","\n","  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  # ----\n","  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","  \n","  x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  # ----\n","  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n","             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = x + skip1\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  # ----\n","  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n","             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = x + skip0\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n","              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n","  x = Activation('relu')(x)\n","  x = BatchNormalization()(x)\n","\n","  # ----\n","  x = tf.keras.layers.SpatialDropout2D(0.2)(x)\n","  x = Conv2D(filters=1, kernel_size=[129,1], strides=[1, 1], padding='same')(x)\n","\n","  model = Model(inputs=inputs, outputs=x)\n","\n","  optimizer = tf.keras.optimizers.Adam(3e-4)\n","  #optimizer = RAdam(total_steps=10000, warmup_proportion=0.1, min_lr=3e-4)\n","\n","  model.compile(optimizer=optimizer, loss='mse', \n","                metrics=[tf.keras.metrics.RootMeanSquaredError('rmse')])\n","  return model"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bq4q9pXY_hFn","colab_type":"text"},"source":["## Model Training"]},{"cell_type":"code","metadata":{"id":"Vj-1-OXp_OA3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596310157364,"user_tz":420,"elapsed":8480,"user":{"displayName":"Colton Davenport","photoUrl":"","userId":"13788767686338694290"}},"outputId":"2b1d252e-e26f-45e8-e23b-0310c374338b"},"source":["model = build_model(l2_strength=0.0)\n","model.summary()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 129, 8, 1)]  0                                            \n","__________________________________________________________________________________________________\n","zero_padding2d (ZeroPadding2D)  (None, 137, 8, 1)    0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 129, 1, 18)   1296        zero_padding2d[0][0]             \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 129, 1, 18)   0           conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 129, 1, 18)   72          activation[0][0]                 \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 129, 1, 30)   2700        batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 129, 1, 30)   0           conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 129, 1, 30)   120         activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 129, 1, 8)    2160        batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 129, 1, 8)    0           conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 129, 1, 8)    32          activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 129, 1, 18)   1296        batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 129, 1, 18)   0           conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 129, 1, 18)   72          activation_3[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 129, 1, 30)   2700        batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 129, 1, 30)   0           conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 129, 1, 30)   120         activation_4[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 129, 1, 8)    2160        batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 129, 1, 8)    0           conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 129, 1, 8)    32          activation_5[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 129, 1, 18)   1296        batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 129, 1, 18)   0           conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 129, 1, 18)   72          activation_6[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 129, 1, 30)   2700        batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 129, 1, 30)   0           conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 129, 1, 30)   120         activation_7[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 129, 1, 8)    2160        batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 129, 1, 8)    0           conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 129, 1, 8)    32          activation_8[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 129, 1, 18)   1296        batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 129, 1, 18)   0           conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 129, 1, 18)   72          activation_9[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 129, 1, 30)   2700        batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","tf_op_layer_AddV2 (TensorFlowOp [(None, 129, 1, 30)] 0           conv2d_10[0][0]                  \n","                                                                 conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 129, 1, 30)   0           tf_op_layer_AddV2[0][0]          \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 129, 1, 30)   120         activation_10[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 129, 1, 8)    2160        batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 129, 1, 8)    0           conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 129, 1, 8)    32          activation_11[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 129, 1, 18)   1296        batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 129, 1, 18)   0           conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 129, 1, 18)   72          activation_12[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 129, 1, 30)   2700        batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","tf_op_layer_AddV2_1 (TensorFlow [(None, 129, 1, 30)] 0           conv2d_13[0][0]                  \n","                                                                 conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 129, 1, 30)   0           tf_op_layer_AddV2_1[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 129, 1, 30)   120         activation_13[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 129, 1, 8)    2160        batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 129, 1, 8)    0           conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 129, 1, 8)    32          activation_14[0][0]              \n","__________________________________________________________________________________________________\n","spatial_dropout2d (SpatialDropo (None, 129, 1, 8)    0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 129, 1, 1)    1033        spatial_dropout2d[0][0]          \n","==================================================================================================\n","Total params: 32,933\n","Trainable params: 32,373\n","Non-trainable params: 560\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BW3qKXYn-agM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":217},"executionInfo":{"status":"ok","timestamp":1596311284883,"user_tz":420,"elapsed":908681,"user":{"displayName":"Colton Davenport","photoUrl":"","userId":"13788767686338694290"}},"outputId":"ab442aac-6b98-40b5-dffc-22cf87999032"},"source":["checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath= CHECKPOINT_DIR + '/' + MODEL_NAME + '.h5', \n","                                                         monitor='val_loss', save_best_only=True)\n","if CONTINUNING_RUN:\n","  model.load_weights(MODEL_WEIGHTS_FILEPATH)\n","\n","model.fit(train_dataset, batch_size=BATCH_SIZE, epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH,validation_data=test_dataset, callbacks=[checkpoint_callback])\n"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","50/50 [==============================] - 183s 4s/step - loss: 1.0684 - rmse: 1.0336 - val_loss: 0.5190 - val_rmse: 0.7204\n","Epoch 2/5\n","50/50 [==============================] - 183s 4s/step - loss: 0.4563 - rmse: 0.6755 - val_loss: 0.4482 - val_rmse: 0.6694\n","Epoch 3/5\n","50/50 [==============================] - 179s 4s/step - loss: 0.4162 - rmse: 0.6452 - val_loss: 0.4252 - val_rmse: 0.6521\n","Epoch 4/5\n","50/50 [==============================] - 179s 4s/step - loss: 0.3649 - rmse: 0.6041 - val_loss: 0.4072 - val_rmse: 0.6381\n","Epoch 5/5\n","50/50 [==============================] - 178s 4s/step - loss: 0.3250 - rmse: 0.5701 - val_loss: 0.3992 - val_rmse: 0.6318\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f981b8222e8>"]},"metadata":{"tags":[]},"execution_count":21}]}]}